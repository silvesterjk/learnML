The design of an agent heavily depends on the type of environment the agent acts upon. We can characterize the types of environments in the following ways:

* In partially observable environments, the agent does not have full information about the state and thus must have an internal estimate of the state of the world. 
* This is in contrast to fully observable environments, where the agent has full information about their state.

* Stochastic environments have uncertainty in the transition model, i.e., taking an action in a specific state may have multiple possible outcomes with different probabilities. 
* This is in contrast to deterministic environments, where taking an action in a state has a single outcome that is guaranteed to happen.

* In multi-agent environments, the agent acts along with other agents. For this reason, the agent might need to randomize its actions to avoid being “predictable” by other agents.
* If the environment does not change as the agent acts on it, it is called static. This is in contrast to dynamic environments that change as the agent interacts with them.

* If an environment has known physics, then the transition model (even if stochastic) is known to the agent, and it can use that when planning a path. 
* If the physics are unknown, the agent will need to take actions deliberately to learn the unknown dynamics.
