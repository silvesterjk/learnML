{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL Deepdive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Expression Language (LCEL) offers several key advantages over legacy chains:\n",
    "\n",
    "1. Composability: LCEL allows you to easily combine different components using the | operator,\n",
    "   making chain creation more intuitive and readable\n",
    "\n",
    "2. Type Safety: LCEL provides better type checking and validation between components,\n",
    "   reducing runtime errors\n",
    "\n",
    "3. Streaming Support: Built-in streaming capabilities that work consistently across\n",
    "   different components\n",
    "\n",
    "4. Flexible Input/Output: Components can handle various input/output types and\n",
    "   automatically convert between them when possible\n",
    "\n",
    "5. Better Testing: The modular nature makes it easier to test individual components\n",
    "   and mock dependencies\n",
    "\n",
    "6. Runtime Optimization: LCEL can automatically optimize execution paths and\n",
    "   handle caching more efficiently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the ice cream cone break up with the sundae?  \\n\\nBecause it found someone sweeter! üç¶'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser() # This is a custom class that is used to parse the output of the model.\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# Pipe in python is __or__ and __ror__ dunder methods, which are bitwise operators used for overloading. \n",
    "# Overloading in Python refers to the ability to have multiple methods and custom classes with the same name but different implementations.\n",
    "\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='tell me a short joke about ice cream', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each component in the chain is a callable/runnable object that can be chained together using the | operator.\n",
    "prompt.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='What did the ice cream cone say to the scoop?  \\n\\n\"I\\'ve got a lot of feelings for you!\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 15, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BclSS1uzXqHpHKd92V4ybXvHp4qaL', 'finish_reason': 'stop', 'logprobs': None}, id='run-42a7944f-b759-456c-acc6-2da83dc27ea7-0', usage_metadata={'input_tokens': 15, 'output_tokens': 22, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content='tell me a short joke about ice cream')]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the ice cream truck break down? It had too many \"scoops\"!'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "ai_msg = AIMessage(content='Why did the ice cream truck break down? It had too many \"scoops\"!')\n",
    "\n",
    "output_parser.invoke(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator Overloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(2+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "result = (2).__add__(4)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StupidAdder:\n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return StupidAdder(self.number + other.number + 42)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "first = StupidAdder(5)\n",
    "second = StupidAdder(10)\n",
    "\n",
    "print(first + second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this \"|\" in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\"\"\"\n",
    "1. Abstract Base Class Pattern:\n",
    "    - `CRunnable` is an abstract class that defines a common interface for processing data. \n",
    "    - Any subclass must implement the `process()` method, ensuring consistent behavior across different runnable objects.\n",
    "\n",
    "2. Chain of Responsibility Implementation:\n",
    "    - Each `CRunnable` can be linked to another through the `next` attribute. \n",
    "    - When `invoke()` is called, it processes the data and automatically passes the result to the next runnable in the chain if one exists.\n",
    "\n",
    "3. Pipe Operator Overloading:\n",
    "    - The `__or__` method allows you to chain runnables using the `|` operator (e.g., `runnable1 | runnable2`).\n",
    "    - Creating a more readable syntax for building processing pipelines.\n",
    "\n",
    "4. Sequence Wrapper Class:\n",
    "    - `CRunnableSequence` is a specialized runnable that wraps two other runnables, executing them in sequence. \n",
    "    - It bypasses the normal `process()` method and directly chains the `invoke()` calls from first to second runnable.\n",
    "\"\"\"\n",
    "\n",
    "class CRunnable(ABC): # CRunnable is an abstract class that defines the interface for a runnable object.\n",
    "    def __init__(self):\n",
    "        self.next = None # next is the argument to the constructor of the class.\n",
    "\n",
    "    @abstractmethod # This is a decorator that ensures that the method is implemented by subclasses.\n",
    "    def process(self, data):\n",
    "        \"\"\"\n",
    "        This method must be implemented by subclasses to define\n",
    "        data processing behavior.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def invoke(self, data):\n",
    "        processed_data = self.process(data)\n",
    "        if self.next is not None:\n",
    "            return self.next.invoke(processed_data)\n",
    "        return processed_data\n",
    "\n",
    "    def __or__(self, other):\n",
    "        return CRunnableSequence(self, other)\n",
    "\n",
    "class CRunnableSequence(CRunnable):\n",
    "    def __init__(self, first, second):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "\n",
    "    def process(self, data):\n",
    "        pass\n",
    "\n",
    "    def invoke(self, data):\n",
    "        first_result = self.first.invoke(data)\n",
    "        return self.second.invoke(first_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTen(CRunnable): # CRunnable is inherited from the abstract class ABC.\n",
    "    def process(self, data):\n",
    "        print(\"AddTen: \", data)\n",
    "        return data + 10\n",
    "\n",
    "class MultiplyByTwo(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"Multiply by 2: \", data)\n",
    "        return data * 2\n",
    "\n",
    "class ConvertToString(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"Convert to string: \", data)\n",
    "        return f\"Result: {data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AddTen()\n",
    "b = MultiplyByTwo()\n",
    "c = ConvertToString()\n",
    "\n",
    "chain = a | b | c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddTen:  10\n",
      "Multiply by 2:  20\n",
      "Convert to string:  40\n",
      "Result: 40\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnables from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnablePassthrough does nothing but pass the input through to the next runnable.\n",
    "chain = RunnablePassthrough() | RunnablePassthrough () | RunnablePassthrough ()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_upper(input: str):\n",
    "    output = input.upper()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnablePassthrough() | RunnableLambda(input_to_upper) | RunnablePassthrough()\n",
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": RunnablePassthrough()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'hello', 'y': 'hello'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input': 'hello', 'input2': 'goodbye'},\n",
       " 'y': {'input': 'hello', 'input2': 'goodbye'}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": lambda z: z[\"input2\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input': 'hello', 'input2': 'goodbye'}, 'y': 'goodbye'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keys_to_uppercase(input: dict):\n",
    "    output = input.get(\"input\", \"not found\").upper()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough() | RunnableLambda(find_keys_to_uppercase), \"y\": lambda z: z[\"input2\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'HELLO', 'y': 'goodbye'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough()})\n",
    "\n",
    "def assign_func(_):\n",
    "    return 100\n",
    "\n",
    "def multiply(input):\n",
    "    return input * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input': 'hello', 'input2': 'goodbye'}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\": RunnablePassthrough()}).assign(extra=RunnableLambda(assign_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': {'input': 'hello', 'input2': 'goodbye'}, 'extra': 100}\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine multiple chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(input: dict):\n",
    "    return input.get(\"extra\", \"Key not found\")\n",
    "\n",
    "def cupper(upper: str):\n",
    "    return str(upper).upper()\n",
    "\n",
    "new_chain = RunnableLambda(extractor) | RunnableLambda(cupper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEST'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain.invoke({\"extra\": \"test\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = chain | new_chain\n",
    "final_chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
