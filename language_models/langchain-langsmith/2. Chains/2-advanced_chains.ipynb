{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/d31w101x0f31vstymvwz8kwr0000gn/T/ipykernel_19411/2486307642.py:8: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'a parrot',\n",
       " 'text': 'Why did the parrot wear a raincoat?\\n\\nBecause it wanted to be a polyunsaturated!'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"input\"], template=\"Tell me a joke about {input}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke(input=\"a parrot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'a parrot',\n",
       " 'language': 'Kannada',\n",
       " 'text': '‡≤í‡≤¨‡≥ç‡≤¨ ‡≤µ‡≥ç‡≤Ø‡≤ï‡≥ç‡≤§‡≤ø‡≤Ø‡≥Å ‡≤é‡≤≥‡≥Ü‡≤Ø ‡≤Æ‡≤∞‡≤¶ ‡≤ï‡≥Ü‡≤≥‡≤ó‡≥Ü ‡≤ï‡≥Å‡≤≥‡≤ø‡≤§ ‡≤ö‡≥Ü‡≤Ç‡≤¶‡≤¶ ‡≤§‡≥ã‡≤ö‡≥Ü‡≤≤‡≥ç‡≤≤‡≥Ä ‡≤π‡≤ï‡≥ç‡≤ï‡≤ø, ‡≤Ü‡≤ó ‡≤Ü‡≤§‡≤®‡≤ø‡≤ó‡≥Ü ‡≤ï‡≤æ‡≤∞‡≤£ ‡≤ï‡≥á‡≤≥‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≤æ‡≤®‡≥Ü. \\n\"‡≤®‡≤æ‡≤®‡≥ç ‡≤Æ‡≤æ‡≤§‡≤æ‡≤°‡≥ç‡≤§‡≥Ä‡≤®‡≤ø!\" ‡≤é‡≤®‡≥ç‡≤®‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤§‡≥ç‡≤§‡≥Å.\\n‡≤Ü ‡≤µ‡≥ç‡≤Ø‡≤ï‡≥ç‡≤§‡≤ø: \"‡≤®‡≤æ‡≤®‡≥ç ‡≤ï‡≥á‡≤≥‡≤ø‡≤¶ ‡≤π‡≤ï‡≥ç‡≤ï‡≤ø‡≤Ø‡≤æ‡≤§?\"\\n‡≤π‡≤ï‡≥ç‡≤ï‡≤ø: \"‡≤®‡≤æ‡≤®‡≥ç ‡≤π‡≥á‡≤≥‡≤ø‡≤¶ ‡≤Æ‡≥Ü‡≤ü‡≥ç‡≤ü‡≤ø‡≤≤‡≥Å ‡≤ï‡≥ä‡≤° ‡≤™‡≥ç‡≤∞‡≤µ‡≥á‡≤∂ ‡≤∏‡≤æ‡≤ß‡≥ç‡≤Ø‡≤µ‡≥Ü?\" \\n\\nüòÑ'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(input_variables=[\"input\", \"language\"], template=\"Tell me a joke about {input} in {language}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke({\"input\": \"a parrot\", \"language\": \"Kannada\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chains can be more complex and not all sequential chains will be as simple as passing a single string as an argument and getting a single string as output for all steps in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "# This is an LLMChain to write a review given a dish name and the experience.\n",
    "prompt_review = PromptTemplate.from_template(\n",
    "    template=\"You ordered {dish_name} and your experience was {experience}. Write a review: \"\n",
    ")\n",
    "chain_review = LLMChain(llm=llm, prompt=prompt_review, output_key=\"review\")\n",
    "\n",
    "# This is an LLMChain to write a follow-up comment given the restaurant review.\n",
    "prompt_comment = PromptTemplate.from_template(\n",
    "    template=\"Given the restaurant review: {review}, write a follow-up comment: \"\n",
    ")\n",
    "chain_comment = LLMChain(llm=llm, prompt=prompt_comment, output_key=\"comment\")\n",
    "\n",
    "# This is an LLMChain to summarize a review.\n",
    "prompt_summary = PromptTemplate.from_template(\n",
    "    template=\"Summarise the review in one short sentence: \\n\\n {comment}\"\n",
    ")\n",
    "chain_summary = LLMChain(llm=llm, prompt=prompt_summary, output_key=\"summary\")\n",
    "\n",
    "# This is an LLMChain to translate a summary into German.\n",
    "prompt_translation = PromptTemplate.from_template(\n",
    "    template=\"Translate the summary to Hindi: \\n\\n {summary}\"\n",
    ")\n",
    "chain_translation = LLMChain(\n",
    "    llm=llm, prompt=prompt_translation, output_key=\"hindi_translation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dish_name': 'Pizza Salami',\n",
       " 'experience': 'It was awful!',\n",
       " 'review': '**Review of Pizza Salami: A Disappointing Experience**\\n\\nI recently ordered a Pizza Salami, hoping for a delicious meal, but unfortunately, my experience was far from satisfactory. \\n\\nFirst off, the pizza arrived later than expected. I understand that sometimes delays happen, but it would have been nice to receive an update or estimate on the delivery time. When it finally arrived, I was met with a soggy crust that reminded me more of cardboard than the crispy base I was hoping for. \\n\\nThe salami itself was a letdown as well. Instead of being flavorful and satisfying, it lacked any real taste and seemed stale. The balance of cheese and sauce was off; there was far too much sauce, making the entire pizza overly soggy and difficult to eat. I ended up picking off some of the toppings just to salvage the experience. \\n\\nLastly, the overall presentation was also disappointing. A pizza should be inviting, but this looked unappetizing and thrown together. \\n\\nSadly, I cannot recommend the Pizza Salami based on this experience. I believe every restaurant deserves a second chance, but this was not a good start. For now, I‚Äôll be looking elsewhere for my pizza cravings.',\n",
       " 'comment': \"I'm really sorry to hear about your experience with the Pizza Salami. It sounds like there were multiple issues, from the delayed delivery to the unappetizing pizza itself. It's always disappointing when a meal doesn't meet expectations, especially when you're looking forward to it. \\n\\nHave you considered reaching out to the restaurant to share your feedback? They might appreciate the insight and could potentially address the issues you encountered. It's always important for businesses to know when they‚Äôre not meeting their customers' expectations. I hope your next pizza outing is much better!\",\n",
       " 'summary': 'The review expresses disappointment over a poor experience with a delayed and unappetizing Pizza Salami, suggesting that feedback should be given to the restaurant for improvement.',\n",
       " 'hindi_translation': '‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§∞‡•Ä ‡§∏‡•á ‡§Ü‡§à ‡§î‡§∞ ‡§Ö‡§™‡•ç‡§∞‡§ø‡§Ø ‡§™‡§ø‡§ú‡•ç‡§ú‡§æ ‡§∏‡§≤‡§æ‡§Æ‡•Ä ‡§ï‡•á ‡§∏‡§æ‡§• ‡§è‡§ï ‡§ñ‡§∞‡§æ‡§¨ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§∞‡§æ‡§∂‡§æ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§ ‡§ï‡•Ä ‡§ó‡§à ‡§π‡•à, ‡§Ø‡§π ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡•á‡§§‡•á ‡§π‡•Å‡§è ‡§ï‡§ø ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡•á‡§∏‡•ç‡§§‡§∞‡§æ‡§Ç ‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§¶‡•Ä ‡§ú‡§æ‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è‡•§'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_review, chain_comment, chain_summary, chain_translation],\n",
    "    input_variables=[\"dish_name\", \"experience\"],\n",
    "    output_variables=[\"review\", \"comment\", \"summary\", \"hindi_translation\"],\n",
    ")\n",
    "\n",
    "overall_chain.invoke({\"dish_name\": \"Pizza Salami\", \"experience\": \"It was awful!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Instead of chaining multiple chains together we can also use an LLM to decide which follow up chain is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "positive_template = \"\"\"You are an AI that focuses on the positive side of things. \\\n",
    "Whenever you analyze a text, you look for the positive aspects and highlight them. \\\n",
    "Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "neutral_template = \"\"\"You are an AI that has a neutral perspective. You just provide a balanced analysis of the text, \\\n",
    "not favoring any positive or negative aspects. Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "negative_template = \"\"\"You are an AI that is designed to find the negative aspects in a text. \\\n",
    "You analyze a text and show the potential downsides. Here is the text:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"positive\",\n",
    "        \"description\": \"Good for analyzing positive sentiments\",\n",
    "        \"prompt_template\": positive_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"neutral\",\n",
    "        \"description\": \"Good for analyzing neutral sentiments\",\n",
    "        \"prompt_template\": neutral_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"negative\",\n",
    "        \"description\": \"Good for analyzing negative sentiments\",\n",
    "        \"prompt_template\": negative_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that focuses on the positive side of things. Whenever you analyze a text, you look for the positive aspects and highlight them. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x11b0c5a50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11b5724d0>, root_client=<openai.OpenAI object at 0x11ad4ca50>, root_async_client=<openai.AsyncOpenAI object at 0x11b571e50>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}),\n",
       " 'neutral': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that has a neutral perspective. You just provide a balanced analysis of the text, not favoring any positive or negative aspects. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x11b0c5a50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11b5724d0>, root_client=<openai.OpenAI object at 0x11ad4ca50>, root_async_client=<openai.AsyncOpenAI object at 0x11b571e50>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}),\n",
       " 'negative': LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an AI that is designed to find the negative aspects in a text. You analyze a text and show the potential downsides. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x11b0c5a50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11b5724d0>, root_client=<openai.OpenAI object at 0x11ad4ca50>, root_async_client=<openai.AsyncOpenAI object at 0x11b571e50>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={})}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    # Here we are creating a dictionary of chains, where the key is the name of the chain and the value is the chain itself.\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: Good for analyzing positive sentiments\n",
      "neutral: Good for analyzing neutral sentiments\n",
      "negative: Good for analyzing negative sentiments\n"
     ]
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "negative: {'input': 'I ordered Pizza Salami for $9.99 and it was not good!'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I ordered Pizza Salami for $9.99 and it was not good!',\n",
       " 'text': 'The negative aspects of the text are:\\n\\n1. **Quality of Food**: The statement clearly indicates dissatisfaction with the taste or quality of the Pizza Salami, suggesting it did not meet expectations.\\n  \\n2. **Value for Money**: At a price of $9.99, the expectation is that the pizza should be enjoyable. The negative experience implies a lack of value for the amount spent.\\n\\n3. **Expectation vs. Reality**: There\\'s an implied disappointment between what was anticipated (a good pizza) and what was received (a bad one), which can lead to frustration.\\n\\n4. **Potential for Future Hesitance**: The negative experience may cause the individual to hesitate or avoid ordering from the same place again, impacting repeat business.\\n\\n5. **Emotional Response**: The phrase \"it was not good!\" conveys a strong negative emotion which could lead to further dissatisfaction or annoyance.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(), # RouterOutputParser is used to parse the output of the router chain into a dictionary\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=destination_chains[\"neutral\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": \"I ordered Pizza Salami for 9.99$ and it was not good!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
